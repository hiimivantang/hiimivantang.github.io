---
layout: page
title: About
permalink: /about/
---

My name is Ivan Tang. I have a track record of success in delivering technical solutions and driving customer adoption. 

From August 2021 to November 2022, I have been working as a (Presales) Solutions Architect at Databricks, where I have become a trusted advisor for key accounts in ASEAN. I have successfully guided customers in adopting the Databricks Lakehouse Platform on AWS and Azure, leading architecture and machine learning (ML) workshops. My efforts have enabled customers, including a Singapore statutory board and one of Indonesia's top 3 telcos, to scale their end-to-end ML pipelines, implement MLOps, and significantly reduce time-to-insights. I have also conducted workshops on leveraging Databricks' feature store, MLflow Tracking, MLflow Model Registry, and automated model deployments, resulting in accelerated ML lifecycles for customers. In addition, I have proactively implemented projects that improved the efficiency of the field engineering team by 10x and delivered webinars to boost the sales pipeline.

Prior to my role at Databricks, I served as a Solutions Architect at Confluent (Professional Services) from July 2020 to August 2021. During this time, I led customer engagements in APAC, designing, architecting, operating, and maintaining event streaming solutions based on Apache Kafka and Confluent commercial products. I provided advisory services to accelerate the adoption of streaming platforms, resulting in successful business outcomes for enterprises. I ensured deployments were aligned with best practices and met customers' functional and technical needs, resulting in accelerated time to value.

Before my tenure at Confluent, I worked as a Data Scientist at GIC (Internal Audit Department) from June 2018 to June 2020. In this role, I derived insights from terabytes of unstructured data, developed anomaly detection engines, and liaised with key stakeholders to understand the use of data in various use cases such as investment risk management, risk assessment, and reporting. I also built a risk assessment engine that provided auditors with the risk criticality of entities across GIC. Additionally, I delivered data science workshops at the firm level, empowering colleagues from front office to corporate services to apply data-driven solutions.

From August 2015 to June 2018, I served as a Consultant at Infocomm Media Development Agency, where I proposed, architected, and built an 18-node Cloudera Hadoop cluster for Division, a PaaS. This initiative allowed developers to run and manage Massively Parallel Processing (MPP) applications without the need to worry about infrastructure. I implemented a data pipeline using tools such as Kafka, Spark Streaming, Parquet, HDFS, Impala, and Hive, resulting in performance improvements for existing data processing. I also developed various solutions utilizing PySpark, C++, and machine learning algorithms. Additionally, I performed sysadmin tasks and managed grant-based projects to unlock business value from telco data for the Retail and Transport industry.

Before that, I worked as a Data Engineer at Visenti Pte Ltd from January 2014 to August 2015, where I proposed, designed, and implemented a real-time anomaly detection system using Apache Storm and NoSQL databases. I played a key role in initiating the shift to a microservice architecture (Docker-based), resulting in a more fault-tolerant system. I developed analytical modules and conducted exploratory data analysis on proprietary sensor data. I also streamlined ETL pipelines, developed REST APIs, and designed and implemented ETL pipelines that ingested, validated, and cleaned data from sensors deployed island-wide.

Early in my career, I gained valuable experience as a Software Engineer at ST Electronics (Info-Software Systems) from June 2010 to December 2013. I was involved in various projects, including the development of a social media monitoring and analytics project and a model and simulation project. I worked with technologies such as C#, Java, Hadoop, NoSQL databases, and agile software development methodologies.

I hold the following certifications: HashiCorp Certified: Terraform Associate (002), Confluent Certified Administrator, Confluent Certified Developer, and Cloudera Certified Developer for Apache Hadoop.

One of my favorite activities is spending time with my family, particularly embarking on unplanned excursions/trips together. Additionally, I enjoy spending entire Sunday afternoons playing Minecraft Dungeons with my three sons. Lastly, I love to workout and I spend more than 3 days per week in the gym.
